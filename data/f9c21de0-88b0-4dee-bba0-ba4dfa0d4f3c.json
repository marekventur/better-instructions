{
  "id": "f9c21de0-88b0-4dee-bba0-ba4dfa0d4f3c",
  "instruction": "Write a script to get the top 10 most frequent words in a corpus.",
  "input": "",
  "output": "#\n# 1. Define the corpus:\n\ncorpus = \"This is a corpus of data to analyze. This dataset will be used to get the top 10 most frequent words.\"\n\n# 2. Tokenize the corpus:\n\nwords = corpus.split()\n\n# 3. Create a dictionary and count each word's frequency:\n\nword_counts = {}\n \nfor word in words:\n    if word in word_counts:\n        word_counts[word] += 1\n    else:\n        word_counts[word] = 1\n\n# 4. Sort the word counts list:\n\nsorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n\n# 5. Print the top 10 words:\n\nprint(\"The top 10 most frequent words are:\")\nfor word, count in sorted_word_counts[:10]:\n    print(word + \": \" + str(count))",
  "license": "stanford-alpaca-unknown",
  "generation-type": "openai-text-davinci-003",
  "generation-reference": "https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json",
  "modified": [],
  "verified": [],
  "tags": []
}