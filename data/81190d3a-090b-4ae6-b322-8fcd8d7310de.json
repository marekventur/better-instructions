{
  "id": "81190d3a-090b-4ae6-b322-8fcd8d7310de",
  "instruction": "List three goals of AI safety research.",
  "input": "",
  "output": "Three goals of AI safety research include minimizing the potential for AI to cause unintentional harm to humans or the environment; ensuring AI systems are robust, secure and free from manipulation; and developing measures to ensure AI systems adhere to ethical standards and international laws.",
  "license": "stanford-alpaca-unknown",
  "generation-type": "openai-text-davinci-003",
  "generation-reference": "https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json",
  "modified": [],
  "verified": [],
  "tags": []
}