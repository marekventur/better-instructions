{
  "id": "552feb6f-db9f-4f35-89c6-77bfd895e0b2",
  "instruction": "Write a summary for the paper given in the input.",
  "input": "Abstract: Fine-tuning continuous prompts for target tasks has recently emerged as a compact alternative to full model fine-tuning. Motivated by these promising results, we investigate the feasibility of extracting a discrete (textual) interpretation of continuous prompts that is faithful to the problem they solve. In practice, we observe a \"wayward\" behavior between the task solved by continuous prompts and their nearest neighbor discrete projections: We can find continuous prompts that solve a task while being projected to an arbitrary text (e.g., definition of a different or even a contradictory task), while being within a very small (2%) margin of the best continuous prompt of the same size for the task. We provide intuitions behind this odd and surprising behavior, as well as extensive empirical analyses quantifying the effect of various parameters. For instance, for larger model sizes we observe higher waywardness, i.e, we can find prompts that more closely map to any arbitrary text with a smaller drop in accuracy. These findings have important implications relating to the difficulty of faithfully interpreting continuous prompts and their generalization across models and tasks, providing guidance for future progress in prompting language models.",
  "output": "This paper presents an exploration of the \u201cwayward\u201d behavior of discrete (textual) interpretations of continuous prompts that are typically used to fine-tune tasks. Through empirical analysis the authors analyze how this waywardness is affected by various parameters such as model size. The research shows that the waywardness increases with model size and provides guidance on faithfully interpreting continuous prompts and furthering research on prompting language models in general.",
  "license": "stanford-alpaca-unknown",
  "generation-type": "openai-text-davinci-003",
  "generation-reference": "https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json",
  "modified": [],
  "verified": [],
  "tags": []
}