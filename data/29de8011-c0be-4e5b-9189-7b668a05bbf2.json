{
  "id": "29de8011-c0be-4e5b-9189-7b668a05bbf2",
  "instruction": "Name 5 common metrics for evaluating a machine learning model",
  "input": "",
  "output": "Common metrics for evaluating a machine learning model include accuracy, precision, recall, F1 score, and ROC AUC score.",
  "license": "stanford-alpaca-unknown",
  "generation-type": "openai-text-davinci-003",
  "generation-reference": "https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json",
  "modified": [],
  "verified": [],
  "tags": []
}